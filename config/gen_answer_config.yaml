name: config of answer generation for arena-hard-v0.1

bench_name: arena-hard-v0.1

# Fore non-thinking models
# temperature: 0.0
# max_tokens: 4096
# For thinking models
temperature: 0.6
# temperature: 0.35
max_tokens: 24576
num_choices: 1

# a list of model to generate answers
model_list:
  # - qwen3-32b-merge-linear_40-original_60-greek-think # DONE
  # - qwen3-32b-merge-linear_50-original_50-greek-think # DONE
  # - qwen3-32b-merge-linear_60-original_40-greek-think # DONE
  # - mistral-small-3.2-24b-instruct-2506 # DONE
  # - krikri-v1.5-self-dpo-checkpoint-240 # DONE
  - krikri-v1.5-self-dpo-checkpoint-472
  # - krikri-v1.5-self-dpo-checkpoint-384 # DONE
  # - krikri-v1.5-self-dpo-checkpoint-432 # DONE
  # - krikri-merge-model_stock-latest_teachers-gemma-r1-dpo # DONE
  # - krikri-neo1-merge-linear-sft-think_50-el-en-mix-1.5ep_25-el_25-en # DONE
  # - krikri-neo1-sft-think_en_el_mix-epoch-1.5 # DONE
  # - krikri-merge-linear-40-latest_60-teachers-gemma-r1-dpo # DONE
  # - krikri-merge-linear-50-latest_50-teachers-gemma-r1-dpo # DONE
  # - krikri-merge-linear-60-latest_40-teachers-gemma-r1-dpo # DONE
  # - krikri-merge-slerp_balanced-base-latest_teachers-gemma-r1-dpo # DONE
  # - krikri-merge-slerp_balanced-base-teachers-gemma-r1-dpo_latest # DONE
  # - qwen3-greek-thinking-dpo # DONE
  # - krikri-neo1-sft-teachers-all #DONE
  # - krikri-neo1-sft-teachers-all-dpo #DONE
  # - krikri-neo1-sft-teachers-gemma-r1 #DONE
  # - krikri-neo1-sft-teachers-gemma-r1-dpo #DONE
  # - krikri-neo1-sft-teachers-r1 #DONE
  # - krikri-neo1-sft-teachers-r1-dpo #DONE
  
  # - krikri-neo1-sft-all
  # - qwen-3-sft-epoch-1
  # - krikri-neo-lora-sft-stage-1
  # - epoch-1
  # - epoch-2
  # - epoch-3
  # - epoch-4
  # - qwen-3-32b-bf16
#  - krikri-8b-instruct-temp0_35
  # - krikri-8b-instruct-with-thinking-temp0_35
#  - qwen-3-1.7b
#  - qwen-3-14b
#  - qwen-3-30b-a3b
#  - qwen-3-32b
  # - claude-3.7-sonnet
  # - deepseek-chat-v3-0324
  # - Llama-4-Scout-17B-16E-Instruct
  # - mistral-small-3.1-24b-instruct-2503
#  - gemma-3-4b-it
#  - gemma-3-12b-it #DONE
#  - gemma-3-27b-it # DONE
#  - base_neo_arcee_fusion_round-2_base # DONE
# - base_neo_arcee_fusion_round-2_base_with_thinking
#  - krikri-annealing-dpo-max-length-norm-dpo-fixes-length-norm-with-thinking
# - deepseek-chat
#  - deepseek-reasoner # DONE
#  - krikri-annealing-dpo_max-length-norm-fixes-checkpoint-1560-with-thinking # DONE
#  - krikri-annealing-dpo-max-length-norm-dpo-fixes-length-norm-round-3-with-IF-checkpoint-2316-with-thinking # 4k misformats 74 times 8k misformats 42 times

#  - krikri-annealing-dpo-max-length-norm-dpo-fixes-length-norm-round-3-with-IF-final-checkpoint # DONE
#  - krikri-annealing-dpo-max-length-norm-dpo-fixes-length-norm-round-3-with-IF-checkpoint-2316 # DONE
#  - krikri-annealing-dpo-max-length-norm-dpo-fixes-length-norm-round-2 # DONE
#  - krikri-annealing-dpo-max-length-norm-dpo-fixes-length-norm-round-1-low-lr # DONE
#  - krikri-annealing-sft-stage2-merge-dpo-max-length-norm-dpo-fixes-length-norm_0.4-dpo_min_0.3dpo_max-length-norm-fixes_on_policy-checkpoint-1560_0.3-dare_tie # DONE
#  - krikri-annealing-sft-stage2-merge-dpo-max-length-norm-dpo-fixes-length-norm_0.45-dpo_min_0.55-dare_tie # DONE
# - krikri-annealing-sft-stage2-merge-dpo-max-length-norm-dpo-fixes-length-norm_0.55-dpo_min_0.45-dare_tie # DONE
#  - krikri-annealing-sft-stage2-dpo_max-length-norm-dpo-fixes_off_policy-length-norm # DONE
#  - krikri-annealing-sft-stage2-dpo_max-length-norm-dpo-fixes-length-norm # DONE
#  - krikri-annealing-sft-stage2-dpo_max-length-norm-simpo
#  - krikri-annealing-sft-stage2-dpo_max-length-norm-fixes_on_policy # DONE
#  - krikri-annealing-sft-stage2-dpo_max-length-norm-fixes_on_policy-checkpoint-1560 # DONE

#  - claude-3.5-sonnet-v2 # DONE
#  - aya-expanse-8b # DONE
#  - llama-3.1-70b # DONE
#  - llama-3.1-8b # DONE
#  - command-r # DONE
#  - command-rplus # DONE
#  - gemma2-9b-it # DONE
#  - mixtral-8x7b-instruct-v0.1 # DONE
#  - mistral-7b-instruct-v0.2 # DONE
#  - gpt-4o # DONE
#  - meltemi-instruct-7b-v1.5-orpo # DONE
#  - gpt-4o-mini # DONE
#  - krikri-annealing-dpo-mixed-run1 # DONE
#  - krikri-annealing-sft-mixed-run1 # DONE
#  - aya-expanse-32b # DONE
#  - krikri-annealing-sft-stage2-run4 # DONE
#  - krikri-annealing-sft-stage2-dpo_max-run4 # DONE
#  - meltemi-annealing-sft-run5 # DONE
#  - krikri-annealing-sft-stage2-dpo_max-epoch-1-run4 # DONE
#  - gemma-2-27b-it # DONE
#  - krikri-annealing-sft-stage2-dpo_min-run4 # DONE
#  - krikri-annealing-sft-stage2-dpo_min-epoch-1-run4 # DONE
#  - krikri-annealing-sft-stage2-dpo_max-length-norm-run4 # DONE
#  - krikri-annealing-sft-stage2-dpo_min-length-norm-run4 # DONE # WITHOUT PROMPT CACHING NOR MODEL LEN
#  - krikri-annealing-sft-stage2-dpo_min-epoch-1-run4 # DONE # WITHOUT PROMPT CACHING NOR MODEL LEN
